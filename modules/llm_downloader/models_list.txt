# Replace these two keys in config.yaml depending on the model you want

# Qwen 2.5 32B
# model_repo: "Qwen/Qwen2.5-32B-Instruct-GGUF"
# model_pattern: "Qwen2.5-32B-Instruct-Q4_K_M*.gguf"

# Qwen 2.5 72B
# model_repo: "Qwen/Qwen2.5-72B-Instruct-GGUF"
# model_pattern: "Qwen2.5-72B-Instruct-Q4_K_M*.gguf"

# Mixtral 8x22B
# model_repo: "mistralai/Mixtral-8x22B-Instruct-v0.1-GGUF"
# model_pattern: "*Q4_K_M*.gguf"

# DeepSeek R1 32B
# model_repo: "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B-GGUF"
# model_pattern: "*Q4_K_M*.gguf"

# Llama 3.1 8B (smaller baseline)
# model_repo: "meta-llama/Llama-3.1-8B-Instruct-GGUF"
# model_pattern: "*Q4_K_M*.gguf"
